# üöÄ Cluster Consul + HAProxy + Node.js Service Mesh

## üìã Objetivos del Proyecto
- Implementar un service mesh completo con **HashiCorp Consul**
- Configurar balanceado de carga din√°mico con **HAProxy** integrado con Consul
- Desplegar aplicaciones **Node.js** con registro autom√°tico de servicios
- Realizar pruebas de carga exhaustivas con **Artillery**
- Demostrar escalabilidad, alta disponibilidad y recuperaci√≥n ante fallos

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Host Machine                              ‚îÇ
‚îÇ  http://localhost:8080  ‚îÇ http://localhost:8404  ‚îÇ :8500    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Load Balancer VM (192.168.50.10)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Consul Server  ‚îÇ ‚îÇ     HAProxy      ‚îÇ ‚îÇ consul-template‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     :8500       ‚îÇ ‚îÇ  Frontend :80    ‚îÇ ‚îÇ   Integration  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    (Leader)     ‚îÇ ‚îÇ   Stats :8404    ‚îÇ ‚îÇ               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ Service Discovery
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                ‚îÇ                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web1 VM (192.168.50.11) ‚îÇ ‚îÇ ‚îÇ   Web2 VM (192.168.50.12) ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚ñº‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Consul Agent + Node.js App                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Service Registration                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Health Checks                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Express Server :3000                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - PM2 Process Management                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estructura del Proyecto

```
consul-haproxy-cluster/
‚îú‚îÄ‚îÄ Vagrantfile                    # Configuraci√≥n de 3 VMs
‚îú‚îÄ‚îÄ start-cluster.sh              # Script de inicio r√°pido
‚îú‚îÄ‚îÄ README.md                     # Esta documentaci√≥n
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ app.js                    # Aplicaci√≥n Node.js principal
‚îÇ   ‚îî‚îÄ‚îÄ package.json              # Dependencias Node.js
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ install_base.sh           # Instalaci√≥n base (Consul, consul-template)
‚îÇ   ‚îú‚îÄ‚îÄ setup_consul_server.sh    # Configuraci√≥n servidor Consul
‚îÇ   ‚îú‚îÄ‚îÄ setup_consul_agent.sh     # Configuraci√≥n agentes Consul
‚îÇ   ‚îú‚îÄ‚îÄ setup_nodejs.sh           # Instalaci√≥n Node.js y PM2
‚îÇ   ‚îú‚îÄ‚îÄ setup_web_service.sh      # Configuraci√≥n servicio web
‚îÇ   ‚îú‚îÄ‚îÄ setup_haproxy.sh          # Configuraci√≥n HAProxy
‚îÇ   ‚îú‚îÄ‚îÄ setup_consul_template.sh  # Configuraci√≥n consul-template
‚îÇ   ‚îî‚îÄ‚îÄ cluster_utils.sh          # Utilidades de gesti√≥n
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ haproxy.ctmpl             # Template din√°mico HAProxy
‚îî‚îÄ‚îÄ artillery/
    ‚îú‚îÄ‚îÄ basic-load-test.yml       # Prueba de carga b√°sica
    ‚îú‚îÄ‚îÄ stress-test.yml           # Prueba de estr√©s
    ‚îú‚îÄ‚îÄ failover-test.yml         # Prueba de failover
    ‚îî‚îÄ‚îÄ functions.js              # Funciones auxiliares Artillery
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos
- **Vagrant** >= 2.3.0
- **VirtualBox** >= 6.1
- **12GB RAM** disponible (4GB para el cluster)
- **Node.js** (para Artillery en host, opcional)

### Instalaci√≥n Autom√°tica

#### Opci√≥n 1: Script de Inicio R√°pido (Recomendado)
```bash
cd consul-haproxy-cluster/
chmod +x start-cluster.sh
./start-cluster.sh
```

#### Opci√≥n 2: Manual
```bash
# Iniciar todas las VMs
vagrant up

# O iniciar una por una
vagrant up loadbalancer
vagrant up web1  
vagrant up web2
```

### Verificaci√≥n de Instalaci√≥n
```bash
# Conectar al load balancer
vagrant ssh loadbalancer

# Verificar estado del cluster
/vagrant/scripts/cluster_utils.sh status

# Probar load balancer
/vagrant/scripts/cluster_utils.sh test-loadbalancer
```

## üîß Componentes del Sistema

### 1. **Consul Cluster**
- **Servidor**: VM loadbalancer (192.168.50.10)
- **Agentes**: web1 y web2 con registro autom√°tico de servicios
- **Funcionalidades**:
  - Service discovery autom√°tico
  - Health checking cada 10 segundos
  - UI web en puerto 8500
  - Encriptaci√≥n de comunicaciones

### 2. **HAProxy Load Balancer**
- **Configuraci√≥n din√°mica** via consul-template
- **Algoritmo**: Round-robin
- **Health checks**: GET /health cada 5 segundos
- **P√°gina 503 personalizada** cuando no hay servicios
- **Stats interface**: Puerto 8404 (admin/admin)

### 3. **Aplicaciones Node.js**
- **Framework**: Express.js
- **Gesti√≥n de procesos**: PM2
- **Endpoints disponibles**:
  - `GET /` - Informaci√≥n del nodo y estad√≠sticas
  - `GET /health` - Health check para Consul
  - `GET /info` - Informaci√≥n detallada del sistema
  - `GET /work?duration=X` - Simula trabajo CPU intensivo
  - `GET /status/X` - Respuesta con c√≥digo espec√≠fico

### 4. **consul-template**
- **Actualizaci√≥n autom√°tica** de HAProxy config
- **Reload** autom√°tico de HAProxy cuando cambian servicios
- **Templating din√°mico** basado en estado de Consul

## üìä URLs de Acceso

### Desde el Host
- **üåê Load Balancer**: http://localhost:8080
- **üìä HAProxy Stats**: http://localhost:8404/stats (admin/admin)  
- **üéõÔ∏è Consul UI**: http://localhost:8500

### Desde las VMs
- **Load Balancer**: http://192.168.50.10
- **HAProxy Stats**: http://192.168.50.10:8404/stats
- **Consul UI**: http://192.168.50.10:8500
- **Web1 Direct**: http://192.168.50.11:3000
- **Web2 Direct**: http://192.168.50.12:3000

## üõ†Ô∏è Scripts de Gesti√≥n

### Script Principal de Utilidades
```bash
# Conectar al load balancer
vagrant ssh loadbalancer
cd /vagrant/scripts
chmod +x cluster_utils.sh

# Ver todos los comandos disponibles
./cluster_utils.sh help
```

### Comandos Principales

#### Monitoreo y Estado
```bash
./cluster_utils.sh status              # Estado general
./cluster_utils.sh consul-status       # Estado Consul
./cluster_utils.sh haproxy-status      # Estado HAProxy
./cluster_utils.sh services            # Servicios registrados
./cluster_utils.sh nodes               # Nodos del cluster
./cluster_utils.sh health              # Verificar salud
```

#### Gesti√≥n de Servicios
```bash
./cluster_utils.sh stop-service web1   # Detener servicio web1
./cluster_utils.sh start-service web1  # Iniciar servicio web1
./cluster_utils.sh reload-haproxy      # Recargar HAProxy
```

#### Escalabilidad
```bash
./cluster_utils.sh scale-up web1       # Escalar web1 (+1 instancia)
./cluster_utils.sh scale-down web1     # Reducir web1 (-1 instancia)
```

#### Pruebas
```bash
./cluster_utils.sh test-loadbalancer   # Prueba b√°sica del LB
./cluster_utils.sh artillery-basic     # Prueba b√°sica Artillery
./cluster_utils.sh artillery-stress    # Prueba de estr√©s
./cluster_utils.sh artillery-failover  # Prueba de failover
```

## üß™ Pruebas de Carga con Artillery

### Instalaci√≥n de Artillery (en host)
```bash
npm install -g artillery
```

### Tipos de Pruebas Disponibles

#### 1. **Prueba B√°sica** (`basic-load-test.yml`)
- **Duraci√≥n**: 4 minutos total
- **Fases**: Warm-up ‚Üí Normal ‚Üí High load
- **M√°x concurrent**: 20 usuarios
- **Escenarios**: Funcionalidad b√°sica, health checks, info endpoints

#### 2. **Prueba de Estr√©s** (`stress-test.yml`)  
- **Duraci√≥n**: 5 minutos total
- **Pico m√°ximo**: 100 usuarios concurrentes
- **Incluye**: Trabajo CPU intensivo, ramp up/down
- **Objetivo**: Encontrar l√≠mites del sistema

#### 3. **Prueba de Failover** (`failover-test.yml`)
- **Duraci√≥n**: 4 minutos total
- **Objetivo**: Probar comportamiento durante fallos
- **Acepta**: C√≥digos 200 y 503
- **Monitorea**: Distribuci√≥n de respuestas

### Ejecuci√≥n Manual de Artillery
```bash
cd artillery/

# Prueba b√°sica
artillery run basic-load-test.yml

# Prueba de estr√©s  
artillery run stress-test.yml

# Prueba de failover
artillery run failover-test.yml
```

## üìà Escenarios de Prueba Recomendados

### **Escenario 1: Operaci√≥n Normal**
1. Iniciar cluster completo
2. Ejecutar prueba b√°sica
3. Verificar distribuci√≥n 50/50 en estad√≠sticas HAProxy
4. Monitorear m√©tricas en Consul UI

```bash
./cluster_utils.sh status
./cluster_utils.sh artillery-basic
# Observar HAProxy stats en http://localhost:8404/stats
```

### **Escenario 2: Simulaci√≥n de Falla**
1. Detener un servicio durante carga
2. Verificar que todo el tr√°fico va al servicio restante
3. Verificar p√°gina 503 cuando no hay servicios
4. Probar recuperaci√≥n autom√°tica

```bash
# Terminal 1: Ejecutar prueba continua
./cluster_utils.sh artillery-failover

# Terminal 2: Simular fallos
./cluster_utils.sh stop-service web1   # Detener web1
# Esperar 30 segundos
./cluster_utils.sh stop-service web2   # Detener web2 (ambos down)
# Esperar 30 segundos  
./cluster_utils.sh start-service web1  # Recuperar web1
./cluster_utils.sh start-service web2  # Recuperar web2
```

### **Escenario 3: Escalabilidad Din√°mica**
1. Escalar servicios bajo carga
2. Verificar que consul-template actualiza HAProxy autom√°ticamente
3. Observar distribuci√≥n de carga ajustarse din√°micamente

```bash
# Terminal 1: Carga sostenida
./cluster_utils.sh artillery-stress

# Terminal 2: Escalar din√°micamente
./cluster_utils.sh scale-up web1      # +1 instancia en web1
sleep 30
./cluster_utils.sh scale-up web2      # +1 instancia en web2
sleep 30
./cluster_utils.sh scale-down web1    # -1 instancia en web1
```

### **Escenario 4: Prueba de Capacidad M√°xima**
1. Incrementar gradualmente la carga
2. Monitorear m√©tricas de sistema (CPU, memoria)
3. Identificar punto de saturaci√≥n

```bash
# Modificar stress-test.yml para aumentar usuarios
# arrivalRate: 100 ‚Üí 200 ‚Üí 500
artillery run stress-test.yml
```

## üìä M√©tricas y Monitoreo

### **HAProxy Stats Dashboard**
Acceder a http://localhost:8404/stats para ver:
- **Session Rate**: Sesiones por segundo
- **Queue**: Peticiones en cola  
- **Response Time**: Latencia promedio
- **Health Status**: Estado de cada backend
- **Bytes In/Out**: Tr√°fico transferido
- **Error Rate**: Porcentaje de errores

### **Consul UI Dashboard** 
Acceder a http://localhost:8500 para ver:
- **Nodes**: Estado de todos los nodos
- **Services**: Servicios registrados y su salud
- **Health Checks**: Resultados de verificaciones
- **Key/Value**: Configuraci√≥n distribuida

### **Node.js App Metrics**
Cada aplicaci√≥n expone m√©tricas en `/info`:
- **CPU Usage**: Carga del procesador
- **Memory Usage**: Uso de memoria
- **Uptime**: Tiempo de actividad
- **Request Count**: Contador de peticiones
- **System Load**: Carga del sistema

## üö® Troubleshooting

### **Problemas Comunes**

#### 1. **Consul no inicia**
```bash
# Verificar logs
vagrant ssh loadbalancer
sudo journalctl -u consul -f

# Verificar configuraci√≥n
sudo consul configtest -config-dir=/etc/consul.d/

# Reiniciar
sudo systemctl restart consul
```

#### 2. **HAProxy no descubre servicios**
```bash
# Verificar consul-template
sudo systemctl status consul-template

# Verificar conectividad a Consul
curl http://127.0.0.1:8500/v1/catalog/service/web

# Forzar regeneraci√≥n de config
sudo systemctl restart consul-template
```

#### 3. **Aplicaciones Node.js no responden**
```bash
vagrant ssh web1
sudo -u vagrant pm2 status
sudo -u vagrant pm2 logs
sudo -u vagrant pm2 restart all
```

#### 4. **Health checks fallan**
```bash
# Verificar endpoint de health
curl http://192.168.50.11:3000/health
curl http://192.168.50.12:3000/health

# Verificar en Consul
consul catalog service web
```

### **Comandos de Diagn√≥stico**
```bash
# Estado completo del cluster
./cluster_utils.sh status

# Logs de todos los servicios
vagrant ssh loadbalancer -c "
    sudo journalctl -u consul --no-pager -n 20
    sudo journalctl -u haproxy --no-pager -n 20  
    sudo journalctl -u consul-template --no-pager -n 20
"

# Reinicio completo
./cluster_utils.sh cleanup
```

## üèÜ Caracter√≠sticas Implementadas

### ‚úÖ **Requerimientos Cumplidos**

1. **‚úÖ Service Mesh con Consul**
   - Cluster con servidor y agentes
   - Service discovery autom√°tico
   - Health checking continuo
   - Comunicaci√≥n encriptada

2. **‚úÖ Load Balancing con HAProxy**  
   - Configuraci√≥n din√°mica via consul-template
   - Round-robin load balancing
   - Health checks integrados
   - Stats interface completa

3. **‚úÖ Aplicaciones Node.js**
   - Auto-registro en Consul
   - Health endpoints
   - M√©tricas de sistema
   - Gesti√≥n con PM2

4. **‚úÖ Escalabilidad**
   - Escalar instancias din√°micamente
   - Detecci√≥n autom√°tica por Consul
   - Actualizaci√≥n autom√°tica de HAProxy
   - Sin downtime durante escalado

5. **‚úÖ Alta Disponibilidad**
   - P√°gina 503 personalizada sin servicios
   - Failover autom√°tico
   - Recovery autom√°tico de servicios
   - Monitoreo continuo

6. **‚úÖ Pruebas de Carga con Artillery**
   - 3 tipos de pruebas configuradas
   - M√©tricas detalladas
   - Distribuci√≥n por nodo
   - Escenarios de falla

### üöÄ **Caracter√≠sticas Adicionales**

- **Aprovisionamiento completamente automatizado**
- **Scripts de gesti√≥n avanzados** (18 comandos)  
- **Monitoreo en tiempo real**
- **Documentaci√≥n exhaustiva**
- **Configuraci√≥n de producci√≥n**
- **Manejo robusto de errores**
- **Logging estructurado**

## üìö Comandos de Referencia R√°pida

### **Gesti√≥n de VMs**
```bash
vagrant up                    # Iniciar todas las VMs
vagrant up loadbalancer       # Solo load balancer
vagrant halt                  # Pausar todas las VMs
vagrant destroy              # Eliminar todas las VMs
vagrant ssh loadbalancer     # Conectar al LB
vagrant status               # Estado de VMs
```

### **Gesti√≥n del Cluster**  
```bash
# Estado y monitoreo
./cluster_utils.sh status
./cluster_utils.sh health
./cluster_utils.sh consul-status
./cluster_utils.sh services

# Pruebas
./cluster_utils.sh test-loadbalancer
./cluster_utils.sh artillery-basic

# Gesti√≥n de servicios
./cluster_utils.sh stop-service web1
./cluster_utils.sh start-service web1
./cluster_utils.sh scale-up web2
```

### **Comandos Consul**
```bash
consul members               # Listar miembros
consul catalog services      # Listar servicios  
consul catalog service web   # Detalles servicio web
consul operator raft list-peers  # Estado del cluster
```

### **Comandos HAProxy**
```bash
sudo systemctl status haproxy
sudo systemctl reload haproxy  
sudo haproxy -c -f /etc/haproxy/haproxy.cfg  # Verificar config
```

## üéØ Casos de Uso Demostrados

### **1. Service Discovery Autom√°tico**
- Los servicios Node.js se registran autom√°ticamente en Consul al iniciarse
- HAProxy descubre nuevos servicios sin configuraci√≥n manual
- Removal autom√°tico de servicios no saludables

### **2. Load Balancing Din√°mico**
- Distribuci√≥n equitativa de carga entre backends disponibles
- Failover autom√°tico cuando un backend falla
- Recovery autom√°tico cuando un backend se recupera

### **3. Escalabilidad Horizontal**
- Agregar/quitar instancias sin downtime
- Balanceador se ajusta autom√°ticamente
- M√©tricas en tiempo real de distribuci√≥n

### **4. Alta Disponibilidad**
- Sistema funciona con 1 o ambos nodos
- P√°ginas de error personalizadas
- Monitoreo continuo de salud

### **5. Observabilidad**
- M√©tricas detalladas en HAProxy y Consul
- Logs estructurados de todos los componentes
- Dashboards web para monitoreo

## üèÅ Conclusiones

Este microproyecto demuestra una implementaci√≥n completa y funcional de:

- **Service Mesh** moderno con Consul
- **Load Balancing** din√°mico con HAProxy
- **Microservicios** Node.js autoregistrados
- **Pruebas de carga** profesionales con Artillery
- **DevOps automation** con Vagrant

### **Valor Educativo**
- Comprensi√≥n profunda de service discovery
- Experiencia pr√°ctica con load balancers modernos
- Manejo de clusters distribuidos
- Testing de performance y reliability
- Automation de infraestructura

### **Aplicabilidad Real**
- Arquitectura escalable para producci√≥n
- Patterns de observabilidad
- Estrategias de deployment
- Testing de cargas reales
- Operational excellence

---

**üéâ ¬°Microproyecto Completado Exitosamente!** 

Este sistema demuestra una arquitectura de microservicios moderna, completa y funcional, lista para experimentos avanzados y aprendizaje hands-on.
